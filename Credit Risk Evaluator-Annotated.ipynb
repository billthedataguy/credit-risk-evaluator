{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 19\n",
    "## William Vann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Prediction: \n",
    "\n",
    "My prediction is that **Logistic Regression (LR) will perform better than Random Forest Classification (RFC)**. \n",
    "\n",
    "One reason is that the credit risk data problem is similar to other problems (like medical disease risk) we've used LR effectively for. We are looking for a prediction of 0 or 1 for credit risk, not a continuous numeric value, and LR is a standard and trusty choice (often the first choice, at least for testing) for such situations. \n",
    "\n",
    "Of course RFC is a good choice for such situations as well, so I've considered what I know about the math underlying each approach to favor LR.  My understanding is that the math underlying LR involves calculation of probabilities, while the math underlying RFC involves a \"majority voting\" scenario among some number of decision trees.  This particular data problem seems more probabilistic to me, as the question \"Is person A a good credit risk (loan_status=0), or a bad credit risk (loan_status=1)?\" seems better answered with \"Yes (with an x% probability\" than \"Yes (a majority of the trees vote Yes)\". I am persuaded on this point even more when I consider that LR admits of a \"threshold\" probability that the data scientist can change, so as a result it seems like it might be more \"fine-tunable\" than RFC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "\n",
    "df = pd.read_csv(\"Resources/lending_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "      <td>77536.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9805.562577</td>\n",
       "      <td>7.292333</td>\n",
       "      <td>49221.949804</td>\n",
       "      <td>0.377318</td>\n",
       "      <td>3.826610</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>19221.949804</td>\n",
       "      <td>0.032243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2093.223153</td>\n",
       "      <td>0.889495</td>\n",
       "      <td>8371.635077</td>\n",
       "      <td>0.081519</td>\n",
       "      <td>1.904426</td>\n",
       "      <td>0.582086</td>\n",
       "      <td>8371.635077</td>\n",
       "      <td>0.176646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8700.000000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>44800.000000</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14800.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9500.000000</td>\n",
       "      <td>7.172000</td>\n",
       "      <td>48100.000000</td>\n",
       "      <td>0.376299</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10400.000000</td>\n",
       "      <td>7.528000</td>\n",
       "      <td>51400.000000</td>\n",
       "      <td>0.416342</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23800.000000</td>\n",
       "      <td>13.235000</td>\n",
       "      <td>105200.000000</td>\n",
       "      <td>0.714829</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>75200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "count  77536.000000   77536.000000     77536.000000    77536.000000   \n",
       "mean    9805.562577       7.292333     49221.949804        0.377318   \n",
       "std     2093.223153       0.889495      8371.635077        0.081519   \n",
       "min     5000.000000       5.250000     30000.000000        0.000000   \n",
       "25%     8700.000000       6.825000     44800.000000        0.330357   \n",
       "50%     9500.000000       7.172000     48100.000000        0.376299   \n",
       "75%    10400.000000       7.528000     51400.000000        0.416342   \n",
       "max    23800.000000      13.235000    105200.000000        0.714829   \n",
       "\n",
       "       num_of_accounts  derogatory_marks    total_debt   loan_status  \n",
       "count     77536.000000      77536.000000  77536.000000  77536.000000  \n",
       "mean          3.826610          0.392308  19221.949804      0.032243  \n",
       "std           1.904426          0.582086   8371.635077      0.176646  \n",
       "min           0.000000          0.000000      0.000000      0.000000  \n",
       "25%           3.000000          0.000000  14800.000000      0.000000  \n",
       "50%           4.000000          0.000000  18100.000000      0.000000  \n",
       "75%           4.000000          1.000000  21400.000000      0.000000  \n",
       "max          16.000000          3.000000  75200.000000      1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75036\n",
       "1     2500\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loan_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9515.627166</td>\n",
       "      <td>7.169118</td>\n",
       "      <td>48062.314089</td>\n",
       "      <td>0.368549</td>\n",
       "      <td>3.565968</td>\n",
       "      <td>0.333533</td>\n",
       "      <td>18062.314089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18507.800000</td>\n",
       "      <td>10.990529</td>\n",
       "      <td>84027.720000</td>\n",
       "      <td>0.640501</td>\n",
       "      <td>11.649600</td>\n",
       "      <td>2.156400</td>\n",
       "      <td>54027.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "loan_status                                                                 \n",
       "0             9515.627166       7.169118     48062.314089        0.368549   \n",
       "1            18507.800000      10.990529     84027.720000        0.640501   \n",
       "\n",
       "             num_of_accounts  derogatory_marks    total_debt  \n",
       "loan_status                                                   \n",
       "0                   3.565968          0.333533  18062.314089  \n",
       "1                  11.649600          2.156400  54027.720000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"loan_status\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9500.0</td>\n",
       "      <td>7.1510</td>\n",
       "      <td>47900.0</td>\n",
       "      <td>0.373695</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18600.0</td>\n",
       "      <td>11.0235</td>\n",
       "      <td>84300.0</td>\n",
       "      <td>0.644128</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "loan_status                                                              \n",
       "0               9500.0         7.1510          47900.0        0.373695   \n",
       "1              18600.0        11.0235          84300.0        0.644128   \n",
       "\n",
       "             num_of_accounts  derogatory_marks  total_debt  \n",
       "loan_status                                                 \n",
       "0                        4.0               0.0     17900.0  \n",
       "1                       12.0               2.0     54300.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"loan_status\"]).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"loan_status\", axis=1).values\n",
    "\n",
    "y = df[\"loan_status\"].values\n",
    "\n",
    "target_names=[\"good risk\", \"bad risk\"] # loan_status=0 or 1, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a scaler to standardize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the scaler with the X_train data.\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train and X_test.\n",
    "# Note that the scaler used to transform X_train and X_test was trained on X_train.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictions with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model \n",
    "\n",
    "model = LogisticRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression Training Data Score: 0.9941876461686614\n",
      "Logisitic Regression Testing Data Score: 0.9939640940982254\n"
     ]
    }
   ],
   "source": [
    "# Score the model\n",
    "\n",
    "print(f\"Logisitic Regression Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Logisitic Regression Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression CONFUSION MATRIX: \n",
      "\n",
      " [[18617   106]\n",
      " [   11   650]]\n",
      "\n",
      "\n",
      "Logisitic Regression CLASSIFICATION REPORT: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   good risk       1.00      0.99      1.00     18723\n",
      "    bad risk       0.86      0.98      0.92       661\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.99      0.96     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "cm_lr = confusion_matrix(y_true, y_pred)\n",
    "cr_lr = classification_report(y_true, y_pred, target_names=target_names)\n",
    "\n",
    "print(f\"Logisitic Regression CONFUSION MATRIX: \\n\\n {cm_lr}\\n\\n\")\n",
    "print(f\"Logisitic Regression CLASSIFICATION REPORT: \\n\\n {cr_lr}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictions with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=500).fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Training Score: 0.9973861604072087\n",
      "Random Forest Classifier Testing Score: 0.9911782913743293\n"
     ]
    }
   ],
   "source": [
    "# Score the model\n",
    "\n",
    "print(f\"Random Forest Classifier Training Score: {clf.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Random Forest Classifier Testing Score: {clf.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier CONFUSION MATRIX: \n",
      "\n",
      " [[18626    97]\n",
      " [   74   587]]\n",
      "\n",
      "\n",
      "Random Forest Classifier CLASSIFICATION REPORT: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   good risk       1.00      0.99      1.00     18723\n",
      "    bad risk       0.86      0.89      0.87       661\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.94      0.93     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "cm_rfc = confusion_matrix(y_true, y_pred)\n",
    "cr_rfc = classification_report(y_true, y_pred, target_names=target_names)\n",
    "\n",
    "print(f\"Random Forest Classifier CONFUSION MATRIX: \\n\\n {cm_rfc}\\n\\n\")\n",
    "print(f\"Random Forest Classifier CLASSIFICATION REPORT: \\n\\n {cr_rfc}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Reflection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:               precision    recall  f1-score   support\n",
      "\n",
      "   good risk       1.00      0.99      1.00     18723\n",
      "    bad risk       0.86      0.98      0.92       661\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.99      0.96     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n",
      "RFC:               precision    recall  f1-score   support\n",
      "\n",
      "   good risk       1.00      0.99      1.00     18723\n",
      "    bad risk       0.86      0.89      0.87       661\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.94      0.93     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"LR: {cr_lr}\")\n",
    "print(f\"RFC: {cr_rfc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression is the Better-Performing Model\n",
    "\n",
    "Looking at the classification reports for the two models, both models perform well on precision, recall, and f1-score for \"good risk\", but less well for the same metrics for \"bad risk\". Nevertheless, LR performed better than RFC on \"bad risk\" recall and f1-score. Therefore, my prediction was confirmed.  \n",
    "\n",
    "After exploring the dataset, it appears that the dataset is somewhat \"lop-sided\" in that only about 3% of the sample had a \"loan status\" value of 1 (i.e., meaning loan was not approved, they were judged to be a \"bad\" credit risk).  Hence, 97% of the sample was approved for a loan, judged to be a \"good\" risk.  My intuition is that we would expect most of the classification models to perform well with such a skew in the training dataset, and that was borne out in our comparison of two of the most-often used binary classification models.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
